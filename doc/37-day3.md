Day 3

https://adventofcode.com/2021/day/3

This challenge involves processing collections of 1s and 0s.

We have a number of lines (which we can think of as rows) and each line is of the same length. The lines contain a number of binary digits ("bits"), 1s and 0s, which we can think of as columns. Here is some example data.

```
00100
11110
10110
10101
```

The first part of the challenge is to scan each column and produce a a result for each column which is the most frequent bit. This resulting value, called the `gamma rate` is then converted to a number.

Then there is another value called the `epsilon rate` which represents the least common bit in that column.

The problem statement doesn't say what we should do if a column has the same number of 1s and 0s, so let's assume that won't happen.

For a row of width 5, it looks like: 

`gamma_rate + episolon_rate = 2^5 - 1`

or

`epsilon_rate xor 11111 = gamma_rate`

So how should we represent this? I'm inclined to parse the bits into a vector of rows, each of which contains a vector of columns.

Then when processing the data scan each row and add to the `1` and `0` count for each column. The accumulated values could be returned in a Vector of two-element arrays. Arrays are good because they are 0-indexed so the 0 bit count can be in the first element, and the 1 bit count is in the second.

Let's create the template for this.





